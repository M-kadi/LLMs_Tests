{
  "qdrant_url": "http://localhost:6333",
  "collection_prefix": "csv_rag",
  "topk_retrieve": 10,
  "topk_use": 3,
  "enable_rerank": false,
  "text_group_lines": 1,
  "embedding_model": "all-minilm:latest",
  "main_model": "gemini-2.0-flash",
  "docs_dir": "D:\\LLM\\LLM_Tests\\LLMs_Tests\\RAG\\rag_data\\my_csvs\\docs",
  "txt_chunk_chars": 900,
  "txt_overlap": 120,
  "batch_size": 64,
  "rerank_prompt_template": "You are a retrieval re-ranker.\nGiven a user question and a list of candidate contexts, select the most relevant items.\nRules:\n- Choose exactly {choose_k} distinct indices.\n- Prefer contexts that directly contain facts needed to answer.\n- Avoid redundant/duplicate contexts.\n- Output ONLY valid JSON, no extra text.\n\nReturn JSON format:\n{{\n  \"selected_indices\": [0, 2, 5],\n  \"reasons\": [\"short reason 1\", \"short reason 2\", \"short reason 3\"]\n}}\n\nQuestion:\n{query}\n\nCandidates:\n{candidates}\n",
  "answer_prompt_template": "You are an assistant that answers using BOTH the retrieved context and the recent conversation history.\nIMPORTANT RULES:\n- Prefer the Context for factual answers.\n- Use History only to keep continuity (follow-ups, pronouns).\n- If neither History nor Context contains the answer, reply exactly: \"\"I don't know based on the provided context.\"\n\"\n- Keep the answer clear and concise.\n\nHistory (last turns):\n{history}\n\nContext:\n{context}\n\nQuestion: {query}\n\nAnswer:",
  "main_provider": "gemini",
  "embedding_provider": "ollama",
  "env_path": "D:\\LLM\\LLM_Tests\\keys.env",
  "redis_url": "redis://localhost:6379",
  "history_turns": 5,
  "app_id": "rag_api",
  "session_id": "default",
  "user_id": "local_user3",
  "history_max_turns": 2000,
  "history_ttl_seconds": 604800
}